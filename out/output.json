{
    "2602.05327": {
        "authors": [
            "Yangbin Yu",
            "Mingyu Yang",
            "Junyou Li",
            "Yiming Gao",
            "Feiyu Liu",
            "Yijun Yang",
            "Zichuan Lin",
            "Jiafei Lyu",
            "Yicheng Liu",
            "Zhicong Lu",
            "Deheng Ye",
            "Jie Jiang"
        ],
        "title": "ProAct: Agentic Lookahead in Interactive Environments",
        "abstract": "arXiv:2602.05327v1 Announce Type: new  Abstract: Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct",
        "arxiv_id": "2602.05327",
        "ARXIVID": "2602.05327",
        "COMMENT": "Matches criterion 3 as it introduces a novel framework (ProAct) for embodied agents with methodological improvements in planning and decision-making, including new techniques like GLAD and MC-Critic.",
        "RELEVANCE": 9,
        "NOVELTY": 8
    },
    "2602.05014": {
        "authors": [
            "Zhanli Li",
            "Huiwen Tian",
            "Lvzhou Luo",
            "Yixuan Cao",
            "Ping Luo"
        ],
        "title": "DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search",
        "abstract": "arXiv:2602.05014v1 Announce Type: new  Abstract: With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in open-domain settings, existing agentic search frameworks commonly treat long documents as flat collections of chunks, underutilizing document-native priors such as hierarchical organization and sequential discourse structure. We introduce DeepRead, a structure-aware, multi-turn document reasoning agent that explicitly operationalizes these priors for long-document question answering. DeepRead leverages LLM-based OCR model to convert PDFs into structured Markdown that preserves headings and paragraph boundaries. It then indexes documents at the paragraph level and assigns each paragraph a coordinate-style metadata key encoding its section identity and in-section order. Building on this representation, DeepRead equips the LLM with two complementary tools: a Retrieve tool that localizes relevant paragraphs while exposing their structural coordinates (with lightweight scanning context), and a ReadSection tool that enables contiguous, order-preserving reading within a specified section and paragraph range. Our experiments demonstrate that DeepRead achieves significant improvements over Search-o1-style agentic search in document question answering. The synergistic effect between retrieval and reading tools is also validated. Our fine-grained behavioral analysis reveals a reading and reasoning paradigm resembling human-like ``locate then read'' behavior.",
        "arxiv_id": "2602.05014",
        "ARXIVID": "2602.05014",
        "COMMENT": "Matches criterion 3 as it introduces a structure-aware reasoning agent (DeepRead) for document question answering, which is relevant to embodied/robotic AI.",
        "RELEVANCE": 7,
        "NOVELTY": 6
    },
    "2602.05073": {
        "authors": [
            "Changdae Oh",
            "Seongheon Park",
            "To Eun Kim",
            "Jiatong Li",
            "Wendi Li",
            "Samuel Yeh",
            "Xuefeng Du",
            "Hamed Hassani",
            "Paul Bogdan",
            "Dawn Song",
            "Sharon Li"
        ],
        "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
        "abstract": "arXiv:2602.05073v1 Announce Type: new  Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents, and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process, a viewpoint that breaks down for interactive agents in an open world. In contrast, we propose a novel perspective, a conditional uncertainty reduction process, that explicitly models reducible uncertainty over an agent's trajectory by highlighting \"interactivity\" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.",
        "arxiv_id": "2602.05073",
        "ARXIVID": "2602.05073",
        "COMMENT": "Matches criterion 3 as it proposes a novel framework for uncertainty quantification in interactive agents, which is relevant to embodied/robotic AI.",
        "RELEVANCE": 7,
        "NOVELTY": 6
    },
    "2602.05353": {
        "authors": [
            "Ruijie Shi",
            "Houbin Zhang",
            "Yuecheng Han",
            "Yuheng Wang",
            "Jingru Fan",
            "Runde Yang",
            "Yufan Dang",
            "Huatao Li",
            "Dewen Liu",
            "Yuan Cheng",
            "Chen Qian"
        ],
        "title": "AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction",
        "abstract": "arXiv:2602.05353v1 Announce Type: new  Abstract: Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration, many deployed agentic systems operate as black boxes to users. We address this by introducing Agentic Workflow Reconstruction (AWR), a new task aiming to synthesize an explicit, interpretable stand-in workflow that approximates a black-box system using only input--output access. We propose AgentXRay, a search-based framework that formulates AWR as a combinatorial optimization problem over discrete agent roles and tool invocations in a chain-structured workflow space. Unlike model distillation, AgentXRay produces editable white-box workflows that match target outputs under an observable, output-based proxy metric, without accessing model parameters. To navigate the vast search space, AgentXRay employs Monte Carlo Tree Search enhanced by a scoring-based Red-Black Pruning mechanism, which dynamically integrates proxy quality with search depth. Experiments across diverse domains demonstrate that AgentXRay achieves higher proxy similarity and reduces token consumption compared to unpruned search, enabling deeper workflow exploration under fixed iteration budgets.",
        "arxiv_id": "2602.05353",
        "ARXIVID": "2602.05353",
        "COMMENT": "Matches criterion 3 as it introduces a novel method (AgentXRay) for workflow reconstruction in agentic systems, which is relevant to embodied/robotic AI.",
        "RELEVANCE": 7,
        "NOVELTY": 6
    },
    "2602.05847": {
        "authors": [
            "Zhangquan Chen",
            "Jiale Tao",
            "Ruihuang Li",
            "Yihao Hu",
            "Ruitao Chen",
            "Zhantao Yang",
            "Xinlei Yu",
            "Haodong Jing",
            "Manyuan Zhang",
            "Shuai Shao",
            "Biao Wang",
            "Qinglin Lu",
            "Ruqi Huang"
        ],
        "title": "OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention",
        "abstract": "arXiv:2602.05847v1 Announce Type: new  Abstract: While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning. OmniVideo-R1 empowers models to \"think with omnimodal cues\" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.",
        "arxiv_id": "2602.05847",
        "ARXIVID": "2602.05847",
        "COMMENT": "Matches criterion 6 (Video Understanding) as it discusses audio-visual reasoning and mixed-modality tasks in video understanding.",
        "RELEVANCE": 5,
        "NOVELTY": 6
    },
    "2602.05818": {
        "authors": [
            "Zihao Jiang",
            "Miao Peng",
            "Zhenyan Shan",
            "Wenjie Xu",
            "Ben Liu",
            "Gong Chen",
            "Ziqi Gao",
            "Min Peng"
        ],
        "title": "TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning",
        "abstract": "arXiv:2602.05818v1 Announce Type: new  Abstract: Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it lack optimization through dynamic interaction with temporal knowledge graphs (TKGs) environments. To address these limitations, we propose \\textbf{TKG-Thinker}, a novel agent equipped with autonomous planning and adaptive retrieval capabilities for reasoning over TKGs. Specifically, TKG-Thinker performs in-depth temporal reasoning through dynamic multi-turn interactions with TKGs via a dual-training strategy. We first apply Supervised Fine-Tuning (SFT) with chain-of thought data to instill core planning capabilities, followed by a Reinforcement Learning (RL) stage that leverages multi-dimensional rewards to refine reasoning policies under intricate temporal constraints. Experimental results on benchmark datasets with three open-source LLMs show that TKG-Thinker achieves state-of-the-art performance and exhibits strong generalization across complex TKGQA settings.",
        "arxiv_id": "2602.05818",
        "ARXIVID": "2602.05818",
        "COMMENT": "Matches criterion 3 (Embodied/Robotic AI: New Benchmarks or Methods) as it introduces a novel agent for reasoning over temporal knowledge graphs with reinforcement learning.",
        "RELEVANCE": 5,
        "NOVELTY": 6
    },
    "2602.05105": {
        "authors": [
            "Rohan Patil",
            "Jai Malegaonkar",
            "Xiao Jiang",
            "Andre Dion",
            "Gaurav S. Sukhatme",
            "Henrik I. Christensen"
        ],
        "title": "GAMMS: Graph based Adversarial Multiagent Modeling Simulator",
        "abstract": "arXiv:2602.05105v1 Announce Type: new  Abstract: As intelligent systems and multi-agent coordination become increasingly central to real-world applications, there is a growing need for simulation tools that are both scalable and accessible. Existing high-fidelity simulators, while powerful, are often computationally expensive and ill-suited for rapid prototyping or large-scale agent deployments. We present GAMMS (Graph based Adversarial Multiagent Modeling Simulator), a lightweight yet extensible simulation framework designed to support fast development and evaluation of agent behavior in environments that can be represented as graphs. GAMMS emphasizes five core objectives: scalability, ease of use, integration-first architecture, fast visualization feedback, and real-world grounding. It enables efficient simulation of complex domains such as urban road networks and communication systems, supports integration with external tools (e.g., machine learning libraries, planning solvers), and provides built-in visualization with minimal configuration. GAMMS is agnostic to policy type, supporting heuristic, optimization-based, and learning-based agents, including those using large language models. By lowering the barrier to entry for researchers and enabling high-performance simulations on standard hardware, GAMMS facilitates experimentation and innovation in multi-agent systems, autonomous planning, and adversarial modeling. The framework is open-source and available at https://github.com/GAMMSim/GAMMS/",
        "arxiv_id": "2602.05105",
        "ARXIVID": "2602.05105",
        "COMMENT": "Matches criterion 3 (Embodied/Robotic AI: New Benchmarks or Methods) as it introduces a new multi-agent simulator for adversarial modeling and planning.",
        "RELEVANCE": 5,
        "NOVELTY": 6
    },
    "2602.05048": {
        "authors": [
            "Zeyu Fang",
            "Tian Lan",
            "Mahdi Imani"
        ],
        "title": "MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation",
        "abstract": "arXiv:2602.05048v1 Announce Type: new  Abstract: Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading to knowledge gaps in joint planning. We consider the problem of discovering optimal interaction strategies for AI agents to actively elicit human inputs in object-driven planning. To this end, we propose Minimal Information Neuro-Symbolic Tree (MINT) to reason about the impact of knowledge gaps and leverage self-play with MINT to optimize the AI agent's elicitation strategies and queries. More precisely, MINT builds a symbolic tree by making propositions of possible human-AI interactions and by consulting a neural planning policy to estimate the uncertainty in planning outcomes caused by remaining knowledge gaps. Finally, we leverage LLM to search and summarize MINT's reasoning process and curate a set of queries to optimally elicit human inputs for best planning performance. By considering a family of extended Markov decision processes with knowledge gaps, we analyze the return guarantee for a given MINT with active human elicitation. Our evaluation on three benchmarks involving unseen/unknown objects of increasing realism shows that MINT-based planning attains near-expert returns by issuing a limited number of questions per task while achieving significantly improved rewards and success rates.",
        "arxiv_id": "2602.05048",
        "ARXIVID": "2602.05048",
        "COMMENT": "Matches criterion 1 (Spatial Intelligence and Embodied Agents) as it discusses reasoning and planning in human-AI teaming with neuro-symbolic methods.",
        "RELEVANCE": 5,
        "NOVELTY": 6
    },
    "2602.05665": {
        "authors": [
            "Chang Yang",
            "Chuang Zhou",
            "Yilin Xiao",
            "Su Dong",
            "Luyao Zhuang",
            "Yujing Zhang",
            "Zhu Wang",
            "Zijin Hong",
            "Zheng Yuan",
            "Zhishang Xiang",
            "Shengyuan Chen",
            "Huachi Zhou",
            "Qinggang Zhang",
            "Ninghao Liu",
            "Jinsong Su",
            "Xinrun Wang",
            "Yi Chang",
            "Xiao Huang"
        ],
        "title": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications",
        "abstract": "arXiv:2602.05665v1 Announce Type: new  Abstract: Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands out as a powerful structure for agent memory due to the intrinsic capabilities to model relational dependencies, organize hierarchical information, and support efficient retrieval. This survey presents a comprehensive review of agent memory from the graph-based perspective. First, we introduce a taxonomy of agent memory, including short-term vs. long-term memory, knowledge vs. experience memory, non-structural vs. structural memory, with an implementation view of graph-based memory. Second, according to the life cycle of agent memory, we systematically analyze the key techniques in graph-based agent memory, covering memory extraction for transforming the data into the contents, storage for organizing the data efficiently, retrieval for retrieving the relevant contents from memory to support reasoning, and evolution for updating the contents in the memory. Third, we summarize the open-sourced libraries and benchmarks that support the development and evaluation of self-evolving agent memory. We also explore diverse application scenarios. Finally, we identify critical challenges and future research directions. This survey aims to offer actionable insights to advance the development of more efficient and reliable graph-based agent memory systems. All the related resources, including research papers, open-source data, and projects, are collected for the community in https://github.com/DEEP-PolyU/Awesome-GraphMemory.",
        "arxiv_id": "2602.05665",
        "ARXIVID": "2602.05665",
        "COMMENT": "Matches criterion 7 as it is a comprehensive survey on graph-based agent memory, which is relevant to embodied agents and their memory systems.",
        "RELEVANCE": 6,
        "NOVELTY": 5
    },
    "2602.05805": {
        "authors": [
            "Kang Chen",
            "Zhuoka Feng",
            "Sihan Zhao",
            "Kai Xiong",
            "Junjie Nian",
            "Yaoning Wang",
            "Changyi Xiao",
            "Yixin Cao"
        ],
        "title": "NEX: Neuron Explore-Exploit Scoring for Label-Free Chain-of-Thought Selection and Model Ranking",
        "abstract": "arXiv:2602.05805v1 Announce Type: new  Abstract: Large language models increasingly spend inference compute sampling multiple chain-of-thought traces or searching over merged checkpoints. This shifts the bottleneck from generation to selection, often without supervision on the target distribution. We show entropy-based exploration proxies follow an inverted-U with accuracy, suggesting extra exploration can become redundant and induce overthinking. We propose NEX, a white-box label-free unsupervised scoring framework that views reasoning as alternating E-phase (exploration) and X-phase (exploitation). NEX detects E-phase as spikes in newly activated MLP neurons per token from sparse activation caches, then uses a sticky two-state HMM to infer E-X phases and credits E-introduced neurons by whether they are reused in the following X span. These signals yield interpretable neuron weights and a single Good-Mass Fraction score to rank candidate responses and merged variants without task answers. Across reasoning benchmarks and Qwen3 merge families, NEX computed on a small unlabeled activation set predicts downstream accuracy and identifies better variants; we further validate the E-X signal with human annotations and provide causal evidence via \"Effective-vs-Redundant\" neuron transfer.",
        "arxiv_id": "2602.05805",
        "ARXIVID": "2602.05805",
        "COMMENT": "Does not match any specific criterion but is tangentially related to general interest in reasoning and model ranking, which could be relevant to vision-language models.",
        "RELEVANCE": 3,
        "NOVELTY": 6
    },
    "2602.05533": {
        "authors": [
            "Zhengyi Guo",
            "Wenpin Tang",
            "Renyuan Xu"
        ],
        "title": "Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach",
        "abstract": "arXiv:2602.05533v1 Announce Type: new  Abstract: We study conditional generation in diffusion models under hard constraints, where generated samples must satisfy prescribed events with probability one. Such constraints arise naturally in safety-critical applications and in rare-event simulation, where soft or reward-based guidance methods offer no guarantee of constraint satisfaction. Building on a probabilistic interpretation of diffusion models, we develop a principled conditional diffusion guidance framework based on Doob's h-transform, martingale representation and quadratic variation process. Specifically, the resulting guided dynamics augment a pretrained diffusion with an explicit drift correction involving the logarithmic gradient of a conditioning function, without modifying the pretrained score network. Leveraging martingale and quadratic-variation identities, we propose two novel off-policy learning algorithms based on a martingale loss and a martingale-covariation loss to estimate h and its gradient using only trajectories from the pretrained model. We provide non-asymptotic guarantees for the resulting conditional sampler in both total variation and Wasserstein distances, explicitly characterizing the impact of score approximation and guidance estimation errors. Numerical experiments demonstrate the effectiveness of the proposed methods in enforcing hard constraints and generating rare-event samples.",
        "arxiv_id": "2602.05533",
        "ARXIVID": "2602.05533",
        "COMMENT": "Does not match any specific criteria but discusses conditional generation in diffusion models, which is tangentially related to generative modeling.",
        "RELEVANCE": 3,
        "NOVELTY": 6
    },
    "2602.05830": {
        "authors": [
            "Shengpu Wang",
            "Yuhao Mao",
            "Yani Zhang",
            "Martin Vechev"
        ],
        "title": "Learning Compact Boolean Networks",
        "abstract": "arXiv:2602.05830v1 Announce Type: new  Abstract: Floating-point neural networks dominate modern machine learning but incur substantial inference cost, motivating interest in Boolean networks for resource-constrained settings. However, learning compact and accurate Boolean networks is challenging due to their combinatorial nature. In this work, we address this challenge from three different angles: learned connections, compact convolutions and adaptive discretization. First, we propose a novel strategy to learn efficient connections with no additional parameters and negligible computational overhead. Second, we introduce a novel convolutional Boolean architecture that exploits the locality with reduced number of Boolean operations than existing methods. Third, we propose an adaptive discretization strategy to reduce the accuracy drop when converting a continuous-valued network into a Boolean one. Extensive results on standard vision benchmarks demonstrate that the Pareto front of accuracy vs. computation of our method significantly outperforms prior state-of-the-art, achieving better accuracy with up to 37x fewer Boolean operations.",
        "arxiv_id": "2602.05830",
        "ARXIVID": "2602.05830",
        "COMMENT": "Does not match any specific criterion but is tangentially related to general interest in efficient neural network architectures, which could be relevant to vision tasks.",
        "RELEVANCE": 3,
        "NOVELTY": 5
    },
    "2602.05143": {
        "authors": [
            "Nengbo Wang",
            "Tuo Liang",
            "Vikash Singh",
            "Chaoda Song",
            "Van Yang",
            "Yu Yin",
            "Jing Ma",
            "Jagdip Singh",
            "Vipin Chaudhary"
        ],
        "title": "HugRAG: Hierarchical Causal Knowledge Graph Design for RAG",
        "abstract": "arXiv:2602.05143v1 Announce Type: new  Abstract: Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack explicit causal modeling, leading to unfaithful or spurious answers. Prior attempts to incorporate causality are typically limited to local or single-document contexts and also suffer from information isolation that arises from modular graph structures, which hinders scalability and cross-module causal reasoning. To address these challenges, we propose HugRAG, a framework that rethinks knowledge organization for graph-based RAG through causal gating across hierarchical modules. HugRAG explicitly models causal relationships to suppress spurious correlations while enabling scalable reasoning over large-scale knowledge graphs. Extensive experiments demonstrate that HugRAG consistently outperforms competitive graph-based RAG baselines across multiple datasets and evaluation metrics. Our work establishes a principled foundation for structured, scalable, and causally grounded RAG systems.",
        "arxiv_id": "2602.05143",
        "ARXIVID": "2602.05143",
        "COMMENT": "Does not match any specific criteria but discusses retrieval-augmented generation with causal knowledge graphs, which is tangentially related to vision-language integration.",
        "RELEVANCE": 3,
        "NOVELTY": 5
    },
    "2602.05709": {
        "authors": [
            "Yihao Ouyang",
            "Shiwei Li",
            "Haozhao Wang",
            "Xiandi Luo",
            "Zhuoqi Hu",
            "Yuetong Song",
            "Qiyu Qin",
            "Yichen Li",
            "Ruixuan Li"
        ],
        "title": "Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions",
        "abstract": "arXiv:2602.05709v1 Announce Type: new  Abstract: Low-rank adaptation (LoRA) approximates the update of a pretrained weight matrix using the product of two low-rank matrices. However, standard LoRA follows an explicit-rank paradigm, where increasing model capacity requires adding more rows or columns (i.e., basis vectors) to the low-rank matrices, leading to substantial parameter growth. In this paper, we find that these basis vectors exhibit significant parameter redundancy and can be compactly represented by lightweight nonlinear functions. Therefore, we propose Generative Low-Rank Adapter (GenLoRA), which replaces explicit basis vector storage with nonlinear basis vector generation. Specifically, GenLoRA maintains a latent vector for each low-rank matrix and employs a set of lightweight radial basis functions (RBFs) to synthesize the basis vectors. Each RBF requires far fewer parameters than an explicit basis vector, enabling higher parameter efficiency in GenLoRA. Extensive experiments across multiple datasets and architectures show that GenLoRA attains higher effective LoRA ranks under smaller parameter budgets, resulting in superior fine-tuning performance. The code is available at https://anonymous.4open.science/r/GenLoRA-1519.",
        "arxiv_id": "2602.05709",
        "ARXIVID": "2602.05709",
        "COMMENT": "Does not match any specific criterion but discusses parameter-efficient fine-tuning, which is tangentially related to general interest in LLMs.",
        "RELEVANCE": 3,
        "NOVELTY": 5
    },
    "2602.05748": {
        "authors": [
            "Amit Kravchik Taub",
            "Fred M. Grabovski",
            "Guy Amit",
            "Yisroel Mirsky"
        ],
        "title": "LeakBoost: Perceptual-Loss-Based Membership Inference Attack",
        "abstract": "arXiv:2602.05748v1 Announce Type: new  Abstract: Membership inference attacks (MIAs) aim to determine whether a sample was part of a model's training set, posing serious privacy risks for modern machine-learning systems. Existing MIAs primarily rely on static indicators, such as loss or confidence, and do not fully leverage the dynamic behavior of models when actively probed. We propose LeakBoost, a perceptual-loss-based interrogation framework that actively probes a model's internal representations to expose hidden membership signals. Given a candidate input, LeakBoost synthesizes an interrogation image by optimizing a perceptual (activation-space) objective, amplifying representational differences between members and non-members. This image is then analyzed by an off-the-shelf membership detector, without modifying the detector itself. When combined with existing membership inference methods, LeakBoost achieves substantial improvements at low false-positive rates across multiple image classification datasets and diverse neural network architectures. In particular, it raises AUC from near-chance levels (0.53-0.62) to 0.81-0.88, and increases TPR at 1 percent FPR by over an order of magnitude compared to strong baseline attacks. A detailed sensitivity analysis reveals that deeper layers and short, low-learning-rate optimization produce the strongest leakage, and that improvements concentrate in gradient-based detectors. LeakBoost thus offers a modular and computationally efficient way to assess privacy risks in white-box settings, advancing the study of dynamic membership inference.",
        "arxiv_id": "2602.05748",
        "ARXIVID": "2602.05748",
        "COMMENT": "Does not match any specific criterion but is tangentially related to machine learning privacy and security, which is outside the specified criteria.",
        "RELEVANCE": 3,
        "NOVELTY": 5
    },
    "2602.05228": {
        "authors": [
            "Guozhi Liu",
            "Weiwei Lin",
            "Tiansheng Huang",
            "Ruichao Mo",
            "Qi Mu",
            "Xiumin Wang",
            "Li Shen"
        ],
        "title": "Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink",
        "abstract": "arXiv:2602.05228v1 Announce Type: new  Abstract: Harmful fine-tuning can invalidate safety alignment of large language models, exposing significant safety risks. In this paper, we utilize the attention sink mechanism to mitigate harmful fine-tuning. Specifically, we first measure a statistic named \\emph{sink divergence} for each attention head and observe that \\emph{different attention heads exhibit two different signs of sink divergence}. To understand its safety implications, we conduct experiments and find that the number of attention heads of positive sink divergence increases along with the increase of the model's harmfulness when undergoing harmful fine-tuning. Based on this finding, we propose a separable sink divergence hypothesis -- \\emph{attention heads associating with learning harmful patterns during fine-tuning are separable by their sign of sink divergence}. Based on the hypothesis, we propose a fine-tuning-stage defense, dubbed Surgery. Surgery utilizes a regularizer for sink divergence suppression, which steers attention heads toward the negative sink divergence group, thereby reducing the model's tendency to learn and amplify harmful patterns. Extensive experiments demonstrate that Surgery improves defense performance by 5.90\\%, 11.25\\%, and 9.55\\% on the BeaverTails, HarmBench, and SorryBench benchmarks, respectively. Source code is available on https://github.com/Lslland/Surgery.",
        "arxiv_id": "2602.05228",
        "ARXIVID": "2602.05228",
        "COMMENT": "Does not match any specific criterion but discusses mitigating harmful fine-tuning in LLMs, which is tangentially related to general interest in LLMs.",
        "RELEVANCE": 3,
        "NOVELTY": 4
    }
}